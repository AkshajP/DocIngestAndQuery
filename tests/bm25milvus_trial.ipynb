{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2994c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Any, Optional, Union\n",
    "import logging\n",
    "from pymilvus import (\n",
    "    connections, \n",
    "    utility,\n",
    "    Collection,\n",
    "    FieldSchema,\n",
    "    CollectionSchema,\n",
    "    DataType,\n",
    "    Function,\n",
    "    FunctionType,\n",
    "    AnnSearchRequest,\n",
    "    RRFRanker,\n",
    "    WeightedRanker\n",
    ")\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Connect to Milvus\n",
    "def connect_to_milvus(host=\"localhost\", port=\"19530\", user=\"\", password=\"\"):\n",
    "    \"\"\"Connect to Milvus server\"\"\"\n",
    "    try:\n",
    "        connections.connect(\n",
    "            alias=\"default\",\n",
    "            host=host,\n",
    "            port=port,\n",
    "            user=user,\n",
    "            password=password\n",
    "        )\n",
    "        logger.info(f\"Connected to Milvus server at {host}:{port}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error connecting to Milvus: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Connect to Milvus server\n",
    "connect_to_milvus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8c08ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define collection name and embedding dimension\n",
    "collection_name = \"document_store_hybrid\"\n",
    "embedding_dim = 3072  # Update this based on your embedding dimension\n",
    "\n",
    "def create_hybrid_collection():\n",
    "    \"\"\"Create a new collection with schema supporting both vector and BM25 search\"\"\"\n",
    "    # Drop collection if it exists\n",
    "    if utility.has_collection(collection_name):\n",
    "        utility.drop_collection(collection_name)\n",
    "        logger.info(f\"Dropped existing collection {collection_name}\")\n",
    "    \n",
    "    # Define fields for collection\n",
    "    fields = [\n",
    "        FieldSchema(name=\"id\", dtype=DataType.VARCHAR, max_length=100, is_primary=True),\n",
    "        FieldSchema(name=\"document_id\", dtype=DataType.VARCHAR, max_length=100),\n",
    "        FieldSchema(name=\"case_id\", dtype=DataType.VARCHAR, max_length=256),\n",
    "        FieldSchema(name=\"chunk_id\", dtype=DataType.VARCHAR, max_length=100),\n",
    "        # Enable analyzer for full-text search on content field\n",
    "        FieldSchema(\n",
    "            name=\"content\", \n",
    "            dtype=DataType.VARCHAR, \n",
    "            max_length=65535,\n",
    "            enable_analyzer=True,  # This enables text analysis for BM25\n",
    "            enable_match=True\n",
    "        ),\n",
    "        FieldSchema(name=\"content_type\", dtype=DataType.VARCHAR, max_length=50),\n",
    "        FieldSchema(name=\"chunk_type\", dtype=DataType.VARCHAR, max_length=50),\n",
    "        FieldSchema(name=\"page_number\", dtype=DataType.INT64),\n",
    "        FieldSchema(name=\"tree_level\", dtype=DataType.INT64),\n",
    "        FieldSchema(name=\"metadata\", dtype=DataType.JSON),\n",
    "        FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=embedding_dim),\n",
    "        # Field for sparse vectors (BM25)\n",
    "        FieldSchema(name=\"sparse\", dtype=DataType.SPARSE_FLOAT_VECTOR)\n",
    "    ]\n",
    "    \n",
    "    # Create schema\n",
    "    schema = CollectionSchema(fields=fields, description=\"Document store with hybrid search\")\n",
    "    \n",
    "    # Create BM25 function to convert content to sparse vector\n",
    "    bm25_function = Function(\n",
    "        name=\"content_bm25_emb\",  # Function name\n",
    "        input_field_names=[\"content\"],  # Name of the field containing text data\n",
    "        output_field_names=[\"sparse\"],  # Name of field to store sparse embeddings\n",
    "        function_type=FunctionType.BM25  # Use BM25 function type\n",
    "    )\n",
    "    \n",
    "    # Add function to schema\n",
    "    schema.add_function(bm25_function)\n",
    "    \n",
    "    # Create collection\n",
    "    collection = Collection(name=collection_name, schema=schema, shards_num=2)\n",
    "    logger.info(f\"Created collection {collection_name}\")\n",
    "    \n",
    "    # Create vector index on embedding field\n",
    "    index_params = {\n",
    "        \"index_type\": \"HNSW\",\n",
    "        \"metric_type\": \"COSINE\",\n",
    "        \"params\": {\"M\": 16, \"efConstruction\": 128}\n",
    "    }\n",
    "    collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "    logger.info(\"Created vector index on embedding field\")\n",
    "    \n",
    "    sparse_index_params = {\n",
    "    \"field_name\": \"sparse\",\n",
    "    \"index_name\": \"sparse_inverted_index\",\n",
    "    \"index_type\": \"SPARSE_INVERTED_INDEX\",   # or \"AUTOINDEX\"\n",
    "    \"metric_type\": \"BM25\",                   # required for full-text\n",
    "    \"params\": {\"inverted_index_algo\": \"DAAT_MAXSCORE\"}  # optional\n",
    "    }\n",
    "    collection.create_index(field_name=\"sparse\", index_params=sparse_index_params)\n",
    "    logger.info(\"Created sparse (BM25) index on field 'sparse'\")\n",
    "    \n",
    "    \n",
    "    # Load collection\n",
    "    collection.load()\n",
    "    logger.info(f\"Collection {collection_name} loaded\")\n",
    "    \n",
    "    return collection\n",
    "\n",
    "# Create collection\n",
    "collection = create_hybrid_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc4a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data_from_existing_collection(source_collection_name=\"document_store\", limit=1000):\n",
    "    \"\"\"\n",
    "    Import data from existing collection to the new hybrid collection\n",
    "    \n",
    "    This function reads data from your current vector store and inserts it\n",
    "    into the new collection with BM25 support\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connect to source collection\n",
    "        source_collection = Collection(name=source_collection_name)\n",
    "        source_collection.load()\n",
    "        logger.info(f\"Loaded source collection {source_collection_name}\")\n",
    "        \n",
    "        # Query data from source collection\n",
    "        results = source_collection.query(\n",
    "            expr=\"\",  # Empty string means all data\n",
    "            output_fields=[\n",
    "                \"id\", \"document_id\", \"case_id\", \"chunk_id\", \"content\", \n",
    "                \"content_type\", \"chunk_type\", \"page_number\", \"tree_level\", \n",
    "                \"metadata\", \"embedding\"\n",
    "            ],\n",
    "            limit=limit\n",
    "        )\n",
    "        \n",
    "        if not results:\n",
    "            logger.warning(\"No data found in source collection\")\n",
    "            return False\n",
    "        \n",
    "        logger.info(f\"Retrieved {len(results)} documents from source collection\")\n",
    "        \n",
    "        # Prepare data for insertion\n",
    "        entities = []\n",
    "        \n",
    "        for entity in results:\n",
    "            # Convert entity to format needed for insertion\n",
    "            # Note: We don't need to provide sparse vector as it's generated automatically by BM25 function\n",
    "            entities.append({\n",
    "                \"id\": entity.get(\"id\"),\n",
    "                \"document_id\": entity.get(\"document_id\"),\n",
    "                \"case_id\": entity.get(\"case_id\"),\n",
    "                \"chunk_id\": entity.get(\"chunk_id\"),\n",
    "                \"content\": entity.get(\"content\"),\n",
    "                \"content_type\": entity.get(\"content_type\", \"text\"),\n",
    "                \"chunk_type\": entity.get(\"chunk_type\", \"original\"),\n",
    "                \"page_number\": entity.get(\"page_number\", -1),\n",
    "                \"tree_level\": entity.get(\"tree_level\", 0),\n",
    "                \"metadata\": entity.get(\"metadata\", {}),\n",
    "                \"embedding\": entity.get(\"embedding\")\n",
    "            })\n",
    "        \n",
    "        # Insert data into new collection\n",
    "        target_collection = Collection(name=collection_name)\n",
    "        result = target_collection.insert(entities)\n",
    "        \n",
    "        target_collection.flush()\n",
    "        logger.info(f\"Imported {len(entities)} entities from {source_collection_name} to {collection_name}\")\n",
    "        \n",
    "        # Return the number of inserted entities\n",
    "        return len(entities)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error importing data: {str(e)}\")\n",
    "        return 0\n",
    "\n",
    "# Import data from existing collection\n",
    "num_imported = import_data_from_existing_collection(limit=1000)\n",
    "print(f\"Imported {num_imported} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2f95f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_sample_data(num_samples=10):\n",
    "    \"\"\"\n",
    "    Insert sample data if no existing collection or import failed\n",
    "    \"\"\"\n",
    "    import uuid\n",
    "    from langchain_ollama import OllamaEmbeddings\n",
    "    \n",
    "    # Initialize embedding model\n",
    "    embedding_model = OllamaEmbeddings(model=\"llama3.2\")\n",
    "    \n",
    "    # Sample texts with varying content\n",
    "    texts = [\n",
    "        \"The transformer architecture revolutionized natural language processing with its attention mechanism.\",\n",
    "        \"Document retrieval systems use vector similarity to find relevant information.\",\n",
    "        \"BM25 is a ranking function used in information retrieval to estimate document relevance.\",\n",
    "        \"Hybrid search combines the benefits of semantic search and keyword-based retrieval.\",\n",
    "        \"Large language models can generate coherent text based on prompts.\",\n",
    "        \"Vector databases store and query high-dimensional embeddings efficiently.\",\n",
    "        \"Knowledge graphs represent information as interconnected entities and relationships.\",\n",
    "        \"Text chunking is crucial for effective document indexing and retrieval.\",\n",
    "        \"Semantic search understands the meaning behind queries rather than just keywords.\",\n",
    "        \"Retrieval augmented generation combines search with text generation for better results.\"\n",
    "    ]\n",
    "    \n",
    "    # Generate embeddings for texts\n",
    "    embeddings = embedding_model.embed_documents(texts)\n",
    "    \n",
    "    # Create entities for insertion\n",
    "    entities = []\n",
    "    \n",
    "    for i, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "        # Create mock document data\n",
    "        entity_id = f\"sample_{i+1}_{uuid.uuid4().hex[:8]}\"\n",
    "        document_id = f\"doc_{i//3 + 1}\"  # Group by document (3 chunks per document)\n",
    "        case_id = \"case_test\"  # Single test case\n",
    "        chunk_id = f\"chunk_{i+1}\"\n",
    "        \n",
    "        entities.append({\n",
    "            \"id\": entity_id,\n",
    "            \"document_id\": document_id,\n",
    "            \"case_id\": case_id,\n",
    "            \"chunk_id\": chunk_id,\n",
    "            \"content\": text,\n",
    "            \"content_type\": \"text\",\n",
    "            \"chunk_type\": \"original\",\n",
    "            \"page_number\": i % 5,  # Mock page numbers\n",
    "            \"tree_level\": 0,  # All are original chunks\n",
    "            \"metadata\": {\"source\": \"sample\"},\n",
    "            \"embedding\": embedding\n",
    "        })\n",
    "    \n",
    "    # Insert data\n",
    "    collection = Collection(name=collection_name)\n",
    "    result = collection.insert(entities)\n",
    "    collection.flush()\n",
    "    \n",
    "    logger.info(f\"Inserted {len(entities)} sample entities\")\n",
    "    return len(entities)\n",
    "\n",
    "# Check if data was imported, if not, insert sample data\n",
    "collection = Collection(name=collection_name)\n",
    "if collection.num_entities == 0:\n",
    "    num_samples = insert_sample_data(num_samples=10)\n",
    "    print(f\"Added {num_samples} sample documents\")\n",
    "else:\n",
    "    print(f\"Collection already has {collection.num_entities} entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26252a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Vector Search (Original approach)\n",
    "def vector_search(query, case_id, document_ids=None, top_k=5):\n",
    "    \"\"\"\n",
    "    Pure vector search using embeddings\n",
    "    \n",
    "    Args:\n",
    "        query: Search query\n",
    "        case_id: Case ID to filter by\n",
    "        document_ids: Optional list of document IDs to filter by\n",
    "        top_k: Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        List of search results and search time\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Generate embedding for query\n",
    "    embedding_model = OllamaEmbeddings(model=\"llama3.2\")\n",
    "    query_embedding = embedding_model.embed_query(query)\n",
    "    \n",
    "    # Prepare search parameters\n",
    "    search_params = {\n",
    "        \"metric_type\": \"COSINE\",\n",
    "        \"params\": {\"ef\": 64}\n",
    "    }\n",
    "    \n",
    "    # Prepare filter expression\n",
    "    expr_parts = []\n",
    "    \n",
    "    # Add case_id filter\n",
    "    expr_parts.append(f'case_id == \"{case_id}\"')\n",
    "    \n",
    "    # Add document_ids filter if provided\n",
    "    if document_ids and len(document_ids) > 0:\n",
    "        if len(document_ids) == 1:\n",
    "            expr_parts.append(f'document_id == \"{document_ids[0]}\"')\n",
    "        else:\n",
    "            doc_list = '\", \"'.join(document_ids)\n",
    "            expr_parts.append(f'document_id in [\"{doc_list}\"]')\n",
    "    \n",
    "    # Combine filter expressions\n",
    "    expr = \" && \".join(expr_parts) if expr_parts else None\n",
    "    \n",
    "    # Execute search\n",
    "    collection = Collection(name=collection_name)\n",
    "    results = collection.search(\n",
    "        data=[query_embedding],\n",
    "        anns_field=\"embedding\",\n",
    "        param=search_params,\n",
    "        limit=top_k,\n",
    "        expr=expr,\n",
    "        output_fields=[\"document_id\", \"chunk_id\", \"content\", \"content_type\", \n",
    "                     \"chunk_type\", \"page_number\", \"tree_level\", \"metadata\"]\n",
    "    )\n",
    "    \n",
    "    # Format results\n",
    "    formatted_results = []\n",
    "    for hits in results:\n",
    "        for hit in hits:\n",
    "            result = {\n",
    "                \"document_id\": hit.entity.get(\"document_id\"),\n",
    "                \"chunk_id\": hit.entity.get(\"chunk_id\"),\n",
    "                \"content\": hit.entity.get(\"content\"),\n",
    "                \"score\": hit.score,\n",
    "                \"content_type\": hit.entity.get(\"content_type\"),\n",
    "                \"page_number\": hit.entity.get(\"page_number\"),\n",
    "                \"search_method\": \"vector\"\n",
    "            }\n",
    "            formatted_results.append(result)\n",
    "    \n",
    "    search_time = time.time() - start_time\n",
    "    logger.info(f\"Vector search completed in {search_time:.3f}s\")\n",
    "    \n",
    "    return formatted_results, search_time\n",
    "\n",
    "# 2. BM25 Search\n",
    "def bm25_search(query, case_id, document_ids=None, top_k=5):\n",
    "    \"\"\"\n",
    "    BM25 search using full-text index\n",
    "    \n",
    "    Args:\n",
    "        query: Search query\n",
    "        case_id: Case ID to filter by\n",
    "        document_ids: Optional list of document IDs to filter by\n",
    "        top_k: Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        List of search results and search time\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Prepare filter expression\n",
    "    expr_parts = []\n",
    "    \n",
    "    # Add case_id filter\n",
    "    expr_parts.append(f\"case_id == '{case_id}'\")\n",
    "    \n",
    "    # Add document_ids filter if provided\n",
    "    if document_ids and len(document_ids) > 0:\n",
    "        if len(document_ids) == 1:\n",
    "            expr_parts.append(f\"document_id == '{document_ids[0]}'\")\n",
    "        else:\n",
    "            doc_list = '\", \"'.join(document_ids)\n",
    "            expr_parts.append(f\"document_id in ['{doc_list}']\")\n",
    "    \n",
    "    # Create the full-text expression for content match\n",
    "    # In Milvus 2.5, we use the MATCH operator for BM25 search\n",
    "    expr_parts.append(f\"TEXT_MATCH(content, '{query}')\")\n",
    "    \n",
    "    # Combine filter expressions\n",
    "    expr = \" && \".join(expr_parts)\n",
    "    \n",
    "    # BM25 search parameters\n",
    "    search_params = {\n",
    "        \"metric_type\": \"BM25\", \n",
    "        \"params\": {\"k1\": 1.5, \"b\": 0.75}  # BM25 parameters\n",
    "    }\n",
    "    \n",
    "    # Execute search\n",
    "    collection = Collection(name=collection_name)\n",
    "    results = collection.search(\n",
    "        data=[query],  # Just pass the query text for BM25\n",
    "        anns_field=\"sparse\",  # Use sparse field for BM25 search\n",
    "        param=search_params,\n",
    "        limit=top_k,\n",
    "        expr=expr,\n",
    "        output_fields=[\"document_id\", \"chunk_id\", \"content\", \"content_type\", \n",
    "                     \"chunk_type\", \"page_number\", \"tree_level\", \"metadata\"]\n",
    "    )\n",
    "    \n",
    "    # Format results\n",
    "    formatted_results = []\n",
    "    for hits in results:\n",
    "        for hit in hits:\n",
    "            result = {\n",
    "                \"document_id\": hit.entity.get(\"document_id\"),\n",
    "                \"chunk_id\": hit.entity.get(\"chunk_id\"),\n",
    "                \"content\": hit.entity.get(\"content\"),\n",
    "                \"score\": hit.score,\n",
    "                \"content_type\": hit.entity.get(\"content_type\"),\n",
    "                \"page_number\": hit.entity.get(\"page_number\"),\n",
    "                \"search_method\": \"bm25\"\n",
    "            }\n",
    "            formatted_results.append(result)\n",
    "    \n",
    "    search_time = time.time() - start_time\n",
    "    logger.info(f\"BM25 search completed in {search_time:.3f}s\")\n",
    "    \n",
    "    return formatted_results, search_time\n",
    "\n",
    "# 3. Hybrid Search (Vector + BM25)\n",
    "def hybrid_search(query, case_id, document_ids=None, top_k=5, vector_weight=0.5):\n",
    "    \"\"\"\n",
    "    Hybrid search by:\n",
    "      1) calling vector_search & bm25_search as-is,\n",
    "      2) min–max normalizing each score list,\n",
    "      3) weighting and fusing them,\n",
    "      4) returning top_k results.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 1) run the two methods exactly as before\n",
    "    vec_hits, _ = vector_search(query, case_id, document_ids, top_k)\n",
    "    bm_hits,  _ = bm25_search(query, case_id, document_ids, top_k)\n",
    "\n",
    "    # 2) extract raw scores (avoid empty list issues)\n",
    "    vec_scores = [h[\"score\"] for h in vec_hits] or [0.0]\n",
    "    bm_scores  = [h[\"score\"] for h in bm_hits]  or [0.0]\n",
    "\n",
    "    vmin, vmax = min(vec_scores), max(vec_scores)\n",
    "    bmin, bmax = min(bm_scores),  max(bm_scores)\n",
    "\n",
    "    def minmax(s, lo, hi):\n",
    "        return 0.0 if hi == lo else (s - lo) / (hi - lo)\n",
    "\n",
    "    # 3) build a merged map keyed by (doc, chunk)\n",
    "    merged = {}\n",
    "    for h in vec_hits:\n",
    "        key = (h[\"document_id\"], h[\"chunk_id\"])\n",
    "        merged.setdefault(key, {\n",
    "            \"document_id\": h[\"document_id\"],\n",
    "            \"chunk_id\":    h[\"chunk_id\"],\n",
    "            \"content\":     h[\"content\"],\n",
    "            \"vector_n\":    0.0,\n",
    "            \"bm25_n\":      0.0\n",
    "        })\n",
    "        merged[key][\"vector_n\"] = minmax(h[\"score\"], vmin, vmax)\n",
    "\n",
    "    for h in bm_hits:\n",
    "        key = (h[\"document_id\"], h[\"chunk_id\"])\n",
    "        merged.setdefault(key, {\n",
    "            \"document_id\": h[\"document_id\"],\n",
    "            \"chunk_id\":    h[\"chunk_id\"],\n",
    "            \"content\":     h[\"content\"],\n",
    "            \"vector_n\":    0.0,\n",
    "            \"bm25_n\":      0.0\n",
    "        })\n",
    "        merged[key][\"bm25_n\"] = minmax(h[\"score\"], bmin, bmax)\n",
    "\n",
    "    # 4) fuse with weights\n",
    "    fused = []\n",
    "    for entry in merged.values():\n",
    "        score = vector_weight * entry[\"vector_n\"] + (1 - vector_weight) * entry[\"bm25_n\"]\n",
    "        fused.append({\n",
    "            **entry,\n",
    "            \"score\": score,\n",
    "            \"search_method\": \"hybrid_minmax_weighted\"\n",
    "        })\n",
    "\n",
    "    # sort and trim\n",
    "    fused.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "    top = fused[:top_k]\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    logger.info(f\"Hybrid‐minmax‐weighted completed in {elapsed:.3f}s\")\n",
    "    return top, elapsed\n",
    "\n",
    "\n",
    "\n",
    "# 3. Hybrid Search (Vector + BM25)\n",
    "# def hybrid_search(query, case_id, document_ids=None, top_k=5, rrf_k=60):\n",
    "#     \"\"\"\n",
    "#     Hybrid search using Reciprocal Rank Fusion (RRF) for fusion of vector and BM25 results.\n",
    "#     \"\"\"\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     # Generate embedding for query\n",
    "#     embedding_model = OllamaEmbeddings(model=\"llama3.2\")\n",
    "#     query_embedding = embedding_model.embed_query(query)\n",
    "\n",
    "#     # Build base filter expression\n",
    "#     expr_parts = [f'case_id == \"{case_id}\"']\n",
    "#     if document_ids:\n",
    "#         if len(document_ids) == 1:\n",
    "#             expr_parts.append(f'document_id == \"{document_ids[0]}\"')\n",
    "#         else:\n",
    "#             docs = '\", \"'.join(document_ids)\n",
    "#             expr_parts.append(f'document_id in [\"{docs}\"]')\n",
    "#     expr = \" && \".join(expr_parts)\n",
    "\n",
    "#     # Vector search request\n",
    "#     vector_request = AnnSearchRequest(\n",
    "#         data=[query_embedding],\n",
    "#         anns_field=\"embedding\",\n",
    "#         param={\"metric_type\": \"COSINE\", \"params\": {\"ef\": 64}},\n",
    "#         limit=top_k,\n",
    "#         expr=expr\n",
    "#     )\n",
    "\n",
    "#     # BM25 search request (adds TEXT_MATCH)\n",
    "#     bm25_request = AnnSearchRequest(\n",
    "#         data=[query],\n",
    "#         anns_field=\"sparse\",\n",
    "#         param={\"metric_type\": \"BM25\", \"params\": {\"k1\": 1.5, \"b\": 0.75}},\n",
    "#         limit=top_k,\n",
    "#         expr=expr + f\" && TEXT_MATCH(content, '{query}')\"\n",
    "#     )\n",
    "\n",
    "#     # e.g. 30% vector, 70% BM25\n",
    "#     ranker = WeightedRanker(0.4, 0.6)\n",
    "\n",
    "#     # Execute hybrid search\n",
    "#     collection = Collection(name=collection_name)\n",
    "#     results = collection.hybrid_search(\n",
    "#         reqs=[vector_request, bm25_request],\n",
    "#         rerank=ranker,\n",
    "#         limit=top_k,\n",
    "#         output_fields=[\n",
    "#             \"document_id\",\"chunk_id\",\"content\",\n",
    "#             \"content_type\",\"chunk_type\",\"page_number\",\n",
    "#             \"tree_level\",\"metadata\"\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     # Format results\n",
    "#     formatted = []\n",
    "#     for hits in results:\n",
    "#         for hit in hits:\n",
    "#             formatted.append({\n",
    "#                 \"document_id\": hit.entity.get(\"document_id\"),\n",
    "#                 \"chunk_id\": hit.entity.get(\"chunk_id\"),\n",
    "#                 \"content\": hit.entity.get(\"content\"),\n",
    "#                 \"score\": hit.score,\n",
    "#                 \"content_type\": hit.entity.get(\"content_type\"),\n",
    "#                 \"page_number\": hit.entity.get(\"page_number\"),\n",
    "#                 \"search_method\": \"hybrid_rrf\"\n",
    "#             })\n",
    "\n",
    "#     logger.info(f\"Hybrid RRF search completed in {time.time() - start_time:.3f}s\")\n",
    "#     return formatted, time.time() - start_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3686e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_search_methods(query, case_id, document_ids=None, top_k=5):\n",
    "    \"\"\"\n",
    "    Compare vector, BM25, and hybrid search methods\n",
    "    \n",
    "    Args:\n",
    "        query: Search query\n",
    "        case_id: Case ID\n",
    "        document_ids: Optional list of document IDs\n",
    "        top_k: Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with results from each method and comparison analysis\n",
    "    \"\"\"\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(f\"Case ID: {case_id}\")\n",
    "    print(f\"Document IDs: {document_ids or 'All'}\")\n",
    "    print(f\"Top K: {top_k}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Execute searches\n",
    "    try:\n",
    "        vector_results, vector_time = vector_search(query, case_id, document_ids, top_k)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Vector search error: {str(e)}\")\n",
    "        vector_results, vector_time = [], 0\n",
    "    \n",
    "    try:\n",
    "        bm25_results, bm25_time = bm25_search(query, case_id, document_ids, top_k)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"BM25 search error: {str(e)}\")\n",
    "        bm25_results, bm25_time = [], 0\n",
    "    \n",
    "    try:\n",
    "        hybrid_results, hybrid_time = hybrid_search(query, case_id, document_ids, top_k)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Hybrid search error: {str(e)}\")\n",
    "        hybrid_results, hybrid_time = [], 0\n",
    "    \n",
    "    # Print timing results\n",
    "    print(\"\\nSearch Performance:\")\n",
    "    print(f\"Vector Search: {vector_time:.3f}s\")\n",
    "    print(f\"BM25 Search: {bm25_time:.3f}s\")\n",
    "    print(f\"Hybrid Search: {hybrid_time:.3f}s\")\n",
    "    \n",
    "    # Create a DataFrame for each result type\n",
    "    if vector_results:\n",
    "        vector_df = pd.DataFrame(vector_results)\n",
    "        vector_df = vector_df[['content', 'score', 'document_id', 'search_method']]\n",
    "        vector_df = vector_df.rename(columns={'score': 'vector_score'})\n",
    "    else:\n",
    "        vector_df = pd.DataFrame(columns=['content', 'vector_score', 'document_id', 'search_method'])\n",
    "    \n",
    "    if bm25_results:\n",
    "        bm25_df = pd.DataFrame(bm25_results)\n",
    "        bm25_df = bm25_df[['content', 'score', 'document_id', 'search_method']]\n",
    "        bm25_df = bm25_df.rename(columns={'score': 'bm25_score'})\n",
    "    else:\n",
    "        bm25_df = pd.DataFrame(columns=['content', 'bm25_score', 'document_id', 'search_method'])\n",
    "    \n",
    "    if hybrid_results:\n",
    "        hybrid_df = pd.DataFrame(hybrid_results)\n",
    "        hybrid_df = hybrid_df[['content', 'score', 'document_id', 'search_method']]\n",
    "        hybrid_df = hybrid_df.rename(columns={'score': 'hybrid_score'})\n",
    "    else:\n",
    "        hybrid_df = pd.DataFrame(columns=['content', 'hybrid_score', 'document_id', 'search_method'])\n",
    "    \n",
    "    # Compare results across methods by content\n",
    "    all_contents = set(vector_df['content'].tolist() + bm25_df['content'].tolist() + hybrid_df['content'].tolist())\n",
    "    \n",
    "    # Create a combined df to analyze overlap\n",
    "    combined_df = pd.DataFrame({'content': list(all_contents)})\n",
    "    \n",
    "    # Merge scores from each method\n",
    "    if not vector_df.empty:\n",
    "        combined_df = combined_df.merge(vector_df[['content', 'vector_score']], on='content', how='left')\n",
    "    else:\n",
    "        combined_df['vector_score'] = None\n",
    "        \n",
    "    if not bm25_df.empty:\n",
    "        combined_df = combined_df.merge(bm25_df[['content', 'bm25_score']], on='content', how='left')\n",
    "    else:\n",
    "        combined_df['bm25_score'] = None\n",
    "        \n",
    "    if not hybrid_df.empty:\n",
    "        combined_df = combined_df.merge(hybrid_df[['content', 'hybrid_score']], on='content', how='left')\n",
    "    else:\n",
    "        combined_df['hybrid_score'] = None\n",
    "    \n",
    "    # Mark which methods found this content\n",
    "    combined_df['found_by_vector'] = ~combined_df['vector_score'].isna()\n",
    "    combined_df['found_by_bm25'] = ~combined_df['bm25_score'].isna()\n",
    "    combined_df['found_by_hybrid'] = ~combined_df['hybrid_score'].isna()\n",
    "    \n",
    "    # Count how many methods found each piece of content\n",
    "    combined_df['methods_count'] = combined_df[['found_by_vector', 'found_by_bm25', 'found_by_hybrid']].sum(axis=1)\n",
    "    \n",
    "    # Sort by hybrid score (if available), then vector score\n",
    "    sort_cols = []\n",
    "    if 'hybrid_score' in combined_df.columns and not combined_df['hybrid_score'].isna().all():\n",
    "        sort_cols.append('hybrid_score')\n",
    "    if 'vector_score' in combined_df.columns and not combined_df['vector_score'].isna().all():\n",
    "        sort_cols.append('vector_score')\n",
    "    if 'bm25_score' in combined_df.columns and not combined_df['bm25_score'].isna().all():\n",
    "        sort_cols.append('bm25_score')\n",
    "    \n",
    "    if sort_cols:\n",
    "        combined_df = combined_df.sort_values(by=sort_cols, ascending=False)\n",
    "    \n",
    "    # Print top results\n",
    "    pd.set_option('display.max_colwidth', 80)\n",
    "    print(\"\\nResults Comparison:\")\n",
    "    print(combined_df.head(top_k).to_string())\n",
    "    \n",
    "    # Analyze overlap between methods\n",
    "    print(\"\\nOverlap Analysis:\")\n",
    "    vector_set = set(vector_df['content'] if not vector_df.empty else [])\n",
    "    bm25_set = set(bm25_df['content'] if not bm25_df.empty else [])\n",
    "    hybrid_set = set(hybrid_df['content'] if not hybrid_df.empty else [])\n",
    "    \n",
    "    print(f\"Total unique contents: {len(all_contents)}\")\n",
    "    print(f\"Vector-only results: {len(vector_set - bm25_set - hybrid_set)}\")\n",
    "    print(f\"BM25-only results: {len(bm25_set - vector_set - hybrid_set)}\")\n",
    "    print(f\"Hybrid-only results: {len(hybrid_set - vector_set - bm25_set)}\")\n",
    "    print(f\"Vector & BM25 overlap: {len(vector_set & bm25_set - hybrid_set)}\")\n",
    "    print(f\"Vector & Hybrid overlap: {len(vector_set & hybrid_set - bm25_set)}\")\n",
    "    print(f\"BM25 & Hybrid overlap: {len(bm25_set & hybrid_set - vector_set)}\")\n",
    "    print(f\"All methods overlap: {len(vector_set & bm25_set & hybrid_set)}\")\n",
    "    \n",
    "    # Create a bar chart comparing the number of results from each method\n",
    "    method_counts = {\n",
    "        'Vector': len(vector_results),\n",
    "        'BM25': len(bm25_results),\n",
    "        'Hybrid': len(hybrid_results)\n",
    "    }\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(method_counts.keys(), method_counts.values())\n",
    "    plt.xlabel('Search Method')\n",
    "    plt.ylabel('Number of Results')\n",
    "    plt.title(f'Number of Results by Search Method - Query: \"{query}\"')\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        \"vector\": vector_results,\n",
    "        \"bm25\": bm25_results,\n",
    "        \"hybrid\": hybrid_results,\n",
    "        \"comparison\": combined_df,\n",
    "        \"timings\": {\n",
    "            \"vector\": vector_time,\n",
    "            \"bm25\": bm25_time,\n",
    "            \"hybrid\": hybrid_time\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Test with different queries\n",
    "def run_test_queries(case_id=\"default\", document_ids=None):\n",
    "    \"\"\"Run test queries and compare search methods\"\"\"\n",
    "    queries = [\n",
    "        \"claimant\",\n",
    "        \"nanghloi depot\",\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    for query in queries:\n",
    "        print(f\"\\n{'='*50}\\nTesting query: '{query}'\\n{'='*50}\")\n",
    "        result = compare_search_methods(query, case_id, document_ids, top_k=5)\n",
    "        results[query] = result\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run test queries\n",
    "test_results = run_test_queries()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docllmRAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
